# 7.3 卷积神经网络

## 目录
- 卷积运算
- 网络结构
- 卷积层
- 池化层


卷积神经网络(Convolutuional Neural Network,简称CNN)，是深度学习技术中最具代表性的一种经典神经网络。卷积是一种特殊的线性运算，是值定义在两个联系实值函数的数学操作。而卷积神经网络就是指在网络结构中至少有一层使用了卷积运算来代替一般的矩阵乘法运算的神经网络。CNN应用非常广泛，尤其是在计算机视觉、图像识别等领域都有着出色的表现，获得了巨大成功。本节将对卷积神经网络做一个简介。


## 7.3.1 卷积运算
卷积操作是定义在两个连续实值函数上的数学操作，为了方便读者理解卷积，通过下面一个例子引出卷积的定义。(本例摘自参考文献《深度学习》)。

假设正在监控一艘自带激光传感器的宇宙飞船，传感器在任意时刻t都能产生一个输出x(t)，x(t)表示飞船在任意时刻t的位置，x和t都是实值。由于在实际过程中有噪声，传感器会受到不同程度的信号干扰，为了更加准确获得飞船的位置，可以对捕获的位置数据进行加权平均处理。显然，时间越近，捕获的数据与实际值约相关，所以不妨将最近的测量数据赋予更高的权值。我们可以通过加权函数w(a)实现，其中a表示测量结果距离当前时刻的时间间隔。这样加权平均后的飞船位置计算公式为：
![](/resource/1.jpg?raw=true)

这个运算就是连续卷积(convolution)的含义，可以表示为一个函数(w)在另外一个函数(x)上的加权叠加，通常被记为：
![](/resource/2.jpg?raw=true)

通常，我们把函数x称为输入(input)，函数w称为核函数(kernel)，输出则称为特征映射(feature map)。

卷积操作满足线性运算的三大规律，即交换律，分配律和结合律。令p=t-a，对于任意的t，当a趋于正无穷时，p趋近于负无穷，反之当a趋于负无穷时，p趋近于正无穷。从而有：
![](/resource/6.jpg?raw=true)

卷积的分配率和结合律可以表示为：
![](/resource/7.jpg?raw=true)

在上述例子中，激光传感器产生的是一个连续的数据，是随时间t不断变化的数值。但是在计算机的业务场景中，连续卷积无法实现，必须离散化，也就是以一定的时间间隔记录相邻的两个数据。还是借用上面的例子，如果激光传感器每隔时间间隔t(t为整数)发送一次数据，那么定义离散形式的卷积为：
![](/resource/3.jpg?raw=true)

如图所示，是二维空间上应用离散卷积的例子，离散卷积可以看作矩阵的乘法，卷积核是一个2*2的二维结构，将卷积核作用在输入数据上，按照从上到下，从左到右的顺序进行运算。
![](/resource/4.jpg?raw=true)

通过上面的例子，可以看到离散卷积本质是有加权的线性运算。在图片识别等领域中，通常也会配置一个宽高为w*h的卷积核，假设输入的图片大小为m*n。卷积核按照从上到下，从左到右的顺序扫描整个图片，会得到一个新的映射空间，其大小为(m-w+1)*(n-h+1)。

图展示了利用卷积核提取图像的特征，该卷积核是一个3*3的带权值的三维结构，被称为高斯-拉普拉斯算子，是在图像处理中非常著名的滤波器。
![](/resource/5.jpg?raw=true)


## 7.3.2 网络结构






